{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d28e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.utils.extmath import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9376677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find second element in a list\n",
    "def sel_second(x):\n",
    "    return x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69843eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove punctuation\n",
    "def strip_punctuation(x):\n",
    "    letters = [i for i in x if i not in string.punctuation]\n",
    "    word = \"\".join(letters)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce37186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize a vector\n",
    "def normalize_vec(x):\n",
    "    if np.sum(x**2)>0:\n",
    "        x_normed = x / np.sqrt(np.sum(x**2))\n",
    "    else:\n",
    "        x_normed = x.copy()\n",
    "    return x_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cb17bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize all vectors in a matrix\n",
    "def normalize_matrix(x):\n",
    "    sum_sq = np.sum(x**2, axis=1)\n",
    "    mag = np.sqrt(sum_sq)\n",
    "    mag[mag == 0] = 1\n",
    "    normed_x = np.transpose(np.transpose(x) / mag)\n",
    "    return normed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32e9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find a word's near neighbors\n",
    "def find_neighbors(x, word_dic, word_matrix, n=30):\n",
    "    word_list = list(word_dic)\n",
    "    sim_list = normalize_vec(word_matrix[word_dic[x]]) @ np.transpose(normalize_matrix(word_matrix))\n",
    "    output = list(zip(word_list, sim_list))\n",
    "    output.sort(key=sel_second, reverse=True)\n",
    "    return output[1:1+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ca2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find cosine simlarity between two word vectors\n",
    "def cosine(x, y, word_dic, word_matrix):\n",
    "    x_vec = normalize_vec(word_matrix[word_dic[x]])\n",
    "    y_vec = normalize_vec(word_matrix[word_dic[y]])\n",
    "    return x_vec @ y_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b04417",
   "metadata": {},
   "source": [
    "The full wikipedia corpus is too large, so I shared a snippet of the corpus to demonstrate how the code works. The snippet of the wikipedia corpus can be found at https://osf.io/6mys9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d14129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt file of wikipedia corpus\n",
    "with open('mini_wiki_corpus.txt', 'r', encoding='utf-8') as f:\n",
    "    df = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23f5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip paragraph indents between documents\n",
    "df = [i.strip() for i in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c535f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert txt file to python lists of words\n",
    "\n",
    "corpus = [] # words grouped by documents\n",
    "all_words = [] # list of all words (helpful to caluculate frequency of words in the corpus)\n",
    "for i in df:\n",
    "    words = i.split(' ') # split string by spaces\n",
    "    words = [x.strip() for x in words] # get rid of any extra white space\n",
    "    words = [x.lower() for x in words] # convert letters to lowercase\n",
    "    words = [strip_punctuation(x) for x in words] # remove punctuation from words\n",
    "    words = [x for x in words if x!=''] # remove any blank entries\n",
    "    corpus.append(words)\n",
    "    all_words.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3872c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequency of all words in corpus in a dictionary object\n",
    "count_dic = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4da827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary object to list object\n",
    "count_list = [(i, count_dic[i]) for i in count_dic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55ea0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by frequency (most frequent words first)\n",
    "count_list.sort(key=sel_second, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7061d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 100,000 most frequent words for the rows of the matrix\n",
    "target_words = [i[0] for i in count_list[:100000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "351a1420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 25,000 most frequent words for columns of the matrix\n",
    "# Excludes the 200 most frequent words, which consist mostly of function words\n",
    "context_words = [i[0] for i in count_list[200:25200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "533d129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary to match words to rows in the matrix\n",
    "target_dic = {}\n",
    "for i in range(0, len(target_words)):\n",
    "    target_dic[target_words[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2035f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary to match words to columns in the matrix\n",
    "context_dic = {}\n",
    "for i in range(0, len(context_words)):\n",
    "    context_dic[context_words[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "256c95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of zeros\n",
    "word_matrix = np.zeros((len(target_dic), len(context_dic)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db93eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define window (two words to left [negative values] and right [positive values])\n",
    "window = [-2, -1, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09a84a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan corpus word-by-word and add counts to word matrix\n",
    "for doc in corpus:\n",
    "    for x in range(0, len(doc)):\n",
    "        if doc[x] in target_dic:\n",
    "            for c in window:\n",
    "                if (x+c) >= 0 and (x+c) < len(doc):\n",
    "                    if doc[x+c] in context_dic:\n",
    "                        word_matrix[target_dic[doc[x]], context_dic[doc[x+c]]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a05a745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate column sums, row sums, and total sum of all co-occurrence counts (needed to calculate Pointwise Mutual Information)\n",
    "colsums = np.sum(word_matrix, axis=0)\n",
    "rowsums = np.sum(word_matrix, axis=1)\n",
    "total = np.sum(word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cda2193a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reidj2\\AppData\\Local\\Temp\\ipykernel_6468\\3106382228.py:4: RuntimeWarning: divide by zero encountered in log2\n",
      "  word_matrix[i] = np.log2((word_matrix[i] * total) / (colsums * rowsums[i]))\n"
     ]
    }
   ],
   "source": [
    "# convert co-occurrence counts to Pointwise Mutual Information (PMI) values\n",
    "for i in range(0, len(word_matrix)):\n",
    "    if np.sum(word_matrix[i]) > 0:\n",
    "        word_matrix[i] = np.log2((word_matrix[i] * total) / (colsums * rowsums[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb6cbca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PMI to Positive PMI (PPMI)\n",
    "word_matrix[word_matrix < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "087acc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Singular Value Decomposition to reduce dimensionality of word matrix\n",
    "word_matrix, s, vt = randomized_svd(word_matrix, n_components=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139852be",
   "metadata": {},
   "source": [
    "Note that for the following examples, the model was trained on a much smaller corpus compared to the full wikipedia, so the neighbors will be different compared to when the model is trained with the full corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a5828ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('basketball', 0.5864471),\n",
       " ('soccer', 0.5713351),\n",
       " ('disaffiliated', 0.5420472),\n",
       " ('heike', 0.52209055),\n",
       " ('rugby', 0.5115758),\n",
       " ('league', 0.5051365),\n",
       " ('deflated', 0.4872858),\n",
       " ('volleyball', 0.4528676),\n",
       " ('softball', 0.45131442),\n",
       " ('hanwell', 0.44987047)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find semantic neighbors of a word\n",
    "find_neighbors('football', target_dic, word_matrix, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc3df184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5115758"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find cosine similarity between two words\n",
    "cosine('football', 'rugby', target_dic, word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b40c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
